{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l13qIL4hQgRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2d295f-bb46-4585-e905-422318e91c15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7af0b8795ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    oov_token = '<OOV>'\n",
        "    idxs = [to_ix[w] if w in to_ix else to_ix[oov_token] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "# Load GloVe embeddings with an OOV token vector\n",
        "def load_glove_embeddings(glove_file):\n",
        "    word_to_ix = {}\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "            if word not in word_to_ix:\n",
        "                word_to_ix[word] = len(word_to_ix)\n",
        "    # Add OOV token to word_to_ix\n",
        "    oov_token = '<OOV>'\n",
        "    word_to_ix[oov_token] = len(word_to_ix)\n",
        "    embedding_dim = len(next(iter(embeddings_index.values())))\n",
        "    # Create embedding matrix including OOV token vector\n",
        "    embedding_matrix = np.zeros((len(word_to_ix), embedding_dim))\n",
        "    for word, i in word_to_ix.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            # Use random initialization for OOV token\n",
        "            embedding_matrix[i] = np.random.normal(size=(embedding_dim,))\n",
        "    return word_to_ix, torch.FloatTensor(embedding_matrix)\n"
      ],
      "metadata": {
        "id": "Pd6BH7PMRu2v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, word_to_ix, tag_to_ix, embedding_dim, hidden_dim, embeddings=None):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        if embeddings is not None:\n",
        "            self.word_embeds = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
        "            self.embedding_dim = embeddings.size(1)\n",
        "        else:\n",
        "            self.word_embeds = nn.Embedding(len(word_to_ix), embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(self.embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "        forward_var = init_alphas\n",
        "        for feat in feats:\n",
        "            alphas_t = []\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []\n",
        "            viterbivars_t = []\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "metadata": {
        "id": "XZCF01ZdR0N5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import json\n",
        "\n",
        "filename = '/content/drive/MyDrive/NLP/pre-trained_embeddings/NER_train.json'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    data_train = json.load(file)\n",
        "\n",
        "filename = '/content/drive/MyDrive/NLP/pre-trained_embeddings/NER_test.json'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    data_test = json.load(file)\n",
        "\n",
        "filename = '/content/drive/MyDrive/NLP/pre-trained_embeddings/NER_val.json'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    data_val = json.load(file)'''\n",
        "\n",
        "import json\n",
        "\n",
        "filename = '/content/drive/MyDrive/NLP/Assignment-2_laptop/ATE_train.json'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    data_train = json.load(file)\n",
        "\n",
        "filename = '/content/drive/MyDrive/NLP/Assignment-2_laptop/ATE_test.json'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    data_test = json.load(file)\n",
        "\n",
        "filename = '/content/drive/MyDrive/NLP/Assignment-2_laptop/ATE_val.json'\n",
        "\n",
        "with open(filename, 'r') as file:\n",
        "    data_val = json.load(file)\n"
      ],
      "metadata": {
        "id": "oOW4ULQBR2j1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data_val\n",
        "tokenized_texts = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over the items in the parsed JSON object\n",
        "for key, value in data.items():\n",
        "    # Extract text and labels for each item\n",
        "    text = value['text']\n",
        "    label_seq = value['labels']\n",
        "\n",
        "    # Tokenize the text (if needed)\n",
        "    tokenized_text = text.split()  # Using simple split for illustration\n",
        "\n",
        "#     Store the tokenized text\n",
        "    tokenized_texts.append(tokenized_text)\n",
        "#     tokenized_texts.append(text)\n",
        "    # Store the labels\n",
        "    labels.append(label_seq)\n",
        "\n",
        "val_data = []\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    pair = [tokenized_texts[i], labels[i]]\n",
        "    val_data.append(pair)\n",
        "\n",
        "data = data_test\n",
        "tokenized_texts = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over the items in the parsed JSON object\n",
        "for key, value in data.items():\n",
        "    # Extract text and labels for each item\n",
        "    text = value['text']\n",
        "    label_seq = value['labels']\n",
        "\n",
        "    # Tokenize the text (if needed)\n",
        "    tokenized_text = text.split()  # Using simple split for illustration\n",
        "\n",
        "#     Store the tokenized text\n",
        "    tokenized_texts.append(tokenized_text)\n",
        "#     tokenized_texts.append(text)\n",
        "    # Store the labels\n",
        "    labels.append(label_seq)\n",
        "\n",
        "test_data = []\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    pair = [tokenized_texts[i], labels[i]]\n",
        "    test_data.append(pair)\n",
        "\n",
        "data = data_train\n",
        "tokenized_texts = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over the items in the parsed JSON object\n",
        "for key, value in data.items():\n",
        "    # Extract text and labels for each item\n",
        "    text = value['text']\n",
        "    label_seq = value['labels']\n",
        "\n",
        "    # Tokenize the text (if needed)\n",
        "    tokenized_text = text.split()  # Using simple split for illustration\n",
        "\n",
        "#     Store the tokenized text\n",
        "    tokenized_texts.append(tokenized_text)\n",
        "#     tokenized_texts.append(text)\n",
        "    # Store the labels\n",
        "    labels.append(label_seq)\n",
        "\n",
        "train_data = []\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    pair = [tokenized_texts[i], labels[i]]\n",
        "    train_data.append(pair)"
      ],
      "metadata": {
        "id": "WRRnzFEWR7bi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {}\n",
        "for tag_sen in labels:\n",
        "    for tag in tag_sen:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n",
        "\n",
        "tag_to_ix[START_TAG] = len(tag_to_ix)\n",
        "tag_to_ix[STOP_TAG] = len(tag_to_ix)\n",
        "tag_to_ix"
      ],
      "metadata": {
        "id": "voP12hn9R-3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773a3545-fd85-450c-bc05-b676cde86563"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': 0, 'B': 1, 'I': 2, '<START>': 3, '<STOP>': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "training_data = train_data\n",
        "validation_data = val_data\n",
        "\n",
        "# Initialize lists to store training and validation loss, and Macro-F1-score\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_f1_scores = []\n",
        "val_f1_scores = []\n",
        "\n",
        "glove_file = '/content/drive/MyDrive/NLP/pre-trained_embeddings/glove.6B.50d.txt'\n",
        "word_to_ix, glove_embeddings = load_glove_embeddings(glove_file)\n",
        "#model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, 50, 50, glove_embeddings)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "# Training loop\n",
        "'''for epoch in range(10):\n",
        "    model.train()  # Set the model to training mode\n",
        "    epoch_train_loss = 0.0\n",
        "    y_true_train = []\n",
        "    y_pred_train = []\n",
        "    for sentence, tags in training_data:\n",
        "        model.zero_grad()\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss.item()\n",
        "\n",
        "        # Record true and predicted tags for training F1-score\n",
        "        with torch.no_grad():\n",
        "            _, predicted_tags = model(sentence_in)\n",
        "            y_true_train.extend(targets.numpy())\n",
        "            y_pred_train.extend(predicted_tags)\n",
        "\n",
        "    # Calculate training loss and F1-score\n",
        "    train_loss = epoch_train_loss / len(training_data)\n",
        "    train_losses.append(train_loss)\n",
        "    train_f1 = f1_score(y_true_train, y_pred_train, average='macro')\n",
        "    train_f1_scores.append(train_f1)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    epoch_val_loss = 0.0\n",
        "    y_true_val = []\n",
        "    y_pred_val = []\n",
        "    for sentence, tags in validation_data:\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        epoch_val_loss += loss.item()\n",
        "\n",
        "        # Record true and predicted tags for validation F1-score\n",
        "        with torch.no_grad():\n",
        "            _, predicted_tags = model(sentence_in)\n",
        "            y_true_val.extend(targets.numpy())\n",
        "            y_pred_val.extend(predicted_tags)\n",
        "\n",
        "    # Calculate validation loss and F1-score\n",
        "    val_loss = epoch_val_loss / len(validation_data)\n",
        "    val_losses.append(val_loss)\n",
        "    val_f1 = f1_score(y_true_val, y_pred_val, average='macro')\n",
        "    val_f1_scores.append(val_f1)\n",
        "    print(f'Epoch [{epoch+1}/10], Train Loss: {epoch_train_loss:.4f}, Val Loss: {val_loss:.4f}, Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}')'''\n"
      ],
      "metadata": {
        "id": "FfqQ9ptqSCy_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "43f499fc-d2a3-497a-9beb-eebdc8637dc3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"for epoch in range(10):\\n    model.train()  # Set the model to training mode\\n    epoch_train_loss = 0.0\\n    y_true_train = []\\n    y_pred_train = []\\n    for sentence, tags in training_data:\\n        model.zero_grad()\\n        sentence_in = prepare_sequence(sentence, word_to_ix)\\n        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\\n        loss = model.neg_log_likelihood(sentence_in, targets)\\n        loss.backward()\\n        optimizer.step()\\n        epoch_train_loss += loss.item()\\n        \\n        # Record true and predicted tags for training F1-score\\n        with torch.no_grad():\\n            _, predicted_tags = model(sentence_in)\\n            y_true_train.extend(targets.numpy())\\n            y_pred_train.extend(predicted_tags)\\n    \\n    # Calculate training loss and F1-score\\n    train_loss = epoch_train_loss / len(training_data)\\n    train_losses.append(train_loss)\\n    train_f1 = f1_score(y_true_train, y_pred_train, average='macro')\\n    train_f1_scores.append(train_f1)\\n    \\n    # Validation\\n    model.eval()  # Set the model to evaluation mode\\n    epoch_val_loss = 0.0\\n    y_true_val = []\\n    y_pred_val = []\\n    for sentence, tags in validation_data:\\n        sentence_in = prepare_sequence(sentence, word_to_ix)\\n        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\\n        loss = model.neg_log_likelihood(sentence_in, targets)\\n        epoch_val_loss += loss.item()\\n        \\n        # Record true and predicted tags for validation F1-score\\n        with torch.no_grad():\\n            _, predicted_tags = model(sentence_in)\\n            y_true_val.extend(targets.numpy())\\n            y_pred_val.extend(predicted_tags)\\n    \\n    # Calculate validation loss and F1-score\\n    val_loss = epoch_val_loss / len(validation_data)\\n    val_losses.append(val_loss)\\n    val_f1 = f1_score(y_true_val, y_pred_val, average='macro')\\n    val_f1_scores.append(val_f1)\\n    print(f'Epoch [{epoch+1}/10], Train Loss: {epoch_train_loss:.4f}, Val Loss: {val_loss:.4f}, Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "'''\n",
        "epochs = range(1, 11)  # 10 epochs\n",
        "\n",
        "# Loss Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_losses, label='Training Loss')\n",
        "plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# F1 Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_f1_scores, label='Training Macro-F1-score')\n",
        "plt.plot(epochs, val_f1_scores, label='Validation Macro-F1-score')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Macro-F1-score')\n",
        "plt.title('Training and Validation Macro-F1-score')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()'''"
      ],
      "metadata": {
        "id": "kWWUmCknSFjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = BiLSTM_CRF(len(word_to_ix), tag_to_ix, 50, 50, glove_embeddings)\n",
        "device = torch.device('cpu')\n",
        "model_path = '/content/drive/MyDrive/A2_19/Part-3/bi_lstm_crf_model_task1_GloVe.pth'\n",
        "model1.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_losses = []\n",
        "test_f1_scores = []\n",
        "\n",
        "model1.eval()\n",
        "y_true_test = []\n",
        "y_pred_test = []\n",
        "for sentence, tags in test_data:\n",
        "    sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "    targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "    #loss = model1.neg_log_likelihood(sentence_in, targets)\n",
        "    #test_losses.append(loss.item())\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, predicted_tags = model1(sentence_in)\n",
        "        y_true_test.extend(targets.numpy())\n",
        "        y_pred_test.extend(predicted_tags)\n",
        "\n",
        "#test_loss = sum(test_losses) / len(test_losses)\n",
        "test_f1 = f1_score(y_true_test, y_pred_test, average='macro')\n",
        "test_f1_scores.append(test_f1)\n",
        "print(f'Test F1: {test_f1:.4f}')\n",
        "print('Accuracy:', accuracy_score(y_true_test, y_pred_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47EGGQFvxEpR",
        "outputId": "296510f4-b8c2-4442-ad6d-0dff2f64370d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test F1: 0.4307\n",
            "Accuracy: 0.903771600300526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = BiLSTM_CRF(len(word_to_ix), tag_to_ix, 50, 50, glove_embeddings)\n",
        "device = torch.device('cpu')\n",
        "model_path = '/content/drive/MyDrive/A2_19/Part-3/bi_lstm_crf_model_task2_GloVe.pth'\n",
        "model1.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_losses = []\n",
        "test_f1_scores = []\n",
        "\n",
        "model1.eval()\n",
        "y_true_test = []\n",
        "y_pred_test = []\n",
        "for sentence, tags in test_data:\n",
        "    sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "    targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "    #loss = model1.neg_log_likelihood(sentence_in, targets)\n",
        "    #test_losses.append(loss.item())\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, predicted_tags = model1(sentence_in)\n",
        "        y_true_test.extend(targets.numpy())\n",
        "        y_pred_test.extend(predicted_tags)\n",
        "\n",
        "#test_loss = sum(test_losses) / len(test_losses)\n",
        "test_f1 = f1_score(y_true_test, y_pred_test, average='macro')\n",
        "test_f1_scores.append(test_f1)\n",
        "print(f'Test F1: {test_f1:.4f}')\n",
        "print('Accuracy:', accuracy_score(y_true_test, y_pred_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfAKkb81zOF2",
        "outputId": "921effbb-b127-4ced-b86d-73ae31799ff3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test F1: 0.7310\n",
            "Accuracy: 0.9168439373428737\n"
          ]
        }
      ]
    }
  ]
}